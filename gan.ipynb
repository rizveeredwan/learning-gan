{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ2o/AIpY4q6XHUlL+oENh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizveeredwan/learning-gan/blob/main/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1LC7_om6WgS"
      },
      "outputs": [],
      "source": [
        "# this notebook is written based on the following article \n",
        "# https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391#:~:text=GAN%20Training&text=Step%201%20%E2%80%94%20Select%20a%20number,both%20fake%20and%20real%20images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, Input, GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "# function for building the discriminator layers\n",
        "def build_discriminator(start_filters, spatial_dim, filter_size):\n",
        "    \n",
        "    # function for building a CNN block for downsampling the image\n",
        "    def add_discriminator_block(x, filters, filter_size):\n",
        "      x = Conv2D(filters, filter_size, padding='same')(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Conv2D(filters, filter_size, padding='same', strides=2)(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = LeakyReLU(0.3)(x)\n",
        "      return x\n",
        "    \n",
        "    # input is an image with shape spatial_dim x spatial_dim and 3 channels\n",
        "    inp = Input(shape=(spatial_dim, spatial_dim, 3))\n",
        "\n",
        "    # design the discrimitor to downsample the image 4x\n",
        "    x = add_discriminator_block(inp, start_filters, filter_size)\n",
        "    x = add_discriminator_block(x, start_filters * 2, filter_size)\n",
        "    x = add_discriminator_block(x, start_filters * 4, filter_size)\n",
        "    x = add_discriminator_block(x, start_filters * 8, filter_size)\n",
        "    \n",
        "    # average and return a binary output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    return Model(inputs=inp, outputs=x)"
      ],
      "metadata": {
        "id": "LD4mFHv86omg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2DTranspose, Reshape\n",
        "\n",
        "def build_generator(start_filters, filter_size, latent_dim):\n",
        "  \n",
        "  # function for building a CNN block for upsampling the image\n",
        "  def add_generator_block(x, filters, filter_size):\n",
        "      x = Conv2DTranspose(filters, filter_size, strides=2, padding='same')(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = LeakyReLU(0.3)(x)\n",
        "      return x\n",
        "\n",
        "  # input is a noise vector \n",
        "  inp = Input(shape=(latent_dim,))\n",
        "\n",
        "  # projection of the noise vector into a tensor with \n",
        "  # same shape as last conv layer in discriminator\n",
        "  x = Dense(4 * 4 * (start_filters * 8), input_dim=latent_dim)(inp)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Reshape(target_shape=(4, 4, start_filters * 8))(x)\n",
        "\n",
        "  # design the generator to upsample the image 4x\n",
        "  x = add_generator_block(x, start_filters * 4, filter_size)\n",
        "  x = add_generator_block(x, start_filters * 2, filter_size)\n",
        "  x = add_generator_block(x, start_filters, filter_size)\n",
        "  x = add_generator_block(x, start_filters, filter_size)    \n",
        "\n",
        "  # turn the output into a 3D tensor, an image with 3 channels \n",
        "  x = Conv2D(3, kernel_size=5, padding='same', activation='tanh')(x)\n",
        "  \n",
        "  return Model(inputs=inp, outputs=x)"
      ],
      "metadata": {
        "id": "1ROdPE7t771_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}